{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Data \n",
    "\n",
    "Missing Values occur because of various reasons, such as, corrupt data, failure to load the information, or incomplete extraction. Handling the missing values is one of the greatest challenges faced by analysts, because making the right decision on how to handle it generates robust data models. Missing values cause a lot of problems when using the dataset for any machine learning algorithm.They hinder with data analysis and data visualization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://drive.google.com/uc?id=1Szk1rEcT280cOdFKq-X0UdlNIsWYvan3\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this kernel , lets look at the following methods to handle missing data\n",
    "\n",
    "**1.Drop all missing Values  \n",
    "2.Drop the values above a certain threshold  \n",
    "3.Imputation using mean ,median and mode  \n",
    "4.Imputation using forward fill and backward fill  \n",
    "5.sklearn Imputer for Numerical Variables  \n",
    "6.sklearn Imputer for Categorical Variables ** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np \n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import category_encoders as ce\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataset \n",
    "df = pd.read_csv(\"../input/widsdatathon2020/training_v2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop all missing Values\n",
    "\n",
    "In this method , we delete a particular row if it has a null value for a particular feature .This method is used only when there are enough samples in the data set. It has to be ensured that there is no bias after data deletion.Removing the data will lead to loss of information which will not give the expected results while predicting the output.All observations that are having null values can be deleted using pandas dropna() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "encounter_id                 0\n",
       "patient_id                   0\n",
       "hospital_id                  0\n",
       "hospital_death               0\n",
       "age                       4228\n",
       "bmi                       3429\n",
       "elective_surgery             0\n",
       "ethnicity                 1395\n",
       "gender                      25\n",
       "height                    1334\n",
       "hospital_admit_source    21409\n",
       "icu_admit_source           112\n",
       "icu_id                       0\n",
       "icu_stay_type                0\n",
       "icu_type                     0\n",
       "pre_icu_los_days             0\n",
       "readmission_status           0\n",
       "weight                    2720\n",
       "albumin_apache           54379\n",
       "apache_2_diagnosis        1662\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of missing values in the data\n",
    "df = df[df.columns[0:20]]\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orginal shape before dropna() (91713, 20)\n",
      "Sshape after dropna() (25349, 20)\n"
     ]
    }
   ],
   "source": [
    "print(\"Orginal shape before dropna()\" ,df.shape)\n",
    "drop = df.dropna()\n",
    "print(\"Sshape after dropna()\" ,drop.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop the values above a certain threshold\n",
    "\n",
    "If the information contained in the variable is not that high, you can drop the variable if it has more than 50% missing values.In this method we are dropping columns with null values above a certain threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91713, 19)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop columns based on threshold limit\n",
    "threshold = len(df) * 0.60\n",
    "df_thresh=df.dropna(axis=1, thresh=threshold)\n",
    "# View columns in the dataset\n",
    "df_thresh.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation using mean ,median and mode\n",
    "\n",
    "This imputation method treats every variable individually, ignoring any interrelationships with other variables and is beneficial for simple linear models and NN. This method may not be suitable for tree based algorithms and this is an approximation which can add variance to the data set. The loss of the data can be negated by this method which yields better results compared to removal of rows and columns.\n",
    "\n",
    "Null values are replaced with mean/median.mode in this method. This is the statistical method of handling Null values.The mean of the numerical column data is used to replace null values when the data is normally distributed. Median is used if the data comprised of outliers. Mode is used when the data having more occurences of a particular value or more frequent value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "impute_df = df[['age','bmi','height']]\n",
    "mean_age = impute_df['age'].mean()\n",
    "median_bmi = impute_df['bmi'].median()\n",
    "mean_height = impute_df['height'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age       4228\n",
       "bmi       3429\n",
       "height    1334\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impute_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null values are replaced with mean/median/mode values by using fillna() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/generic.py:6287: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "age       0\n",
       "bmi       0\n",
       "height    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace Null Values (np.nan) with mean\n",
    "impute_df['age'].fillna(mean_age, inplace=True)\n",
    "\n",
    "impute_df['height'].fillna(mean_height, inplace=True)\n",
    "\n",
    "# Alternate way to fill null values with mean\n",
    "impute_df['bmi'].fillna(median_bmi,inplace=True)\n",
    "\n",
    "impute_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation using forward fill and backward fill \n",
    "\n",
    "Null values can also be replaced by it’s previous value in the column which is called Backward fill or next occurring value in the column which is called Forward fill.The NaN value will remain even after forward filling or back filling if a next or previous value isn’t available or it is also a NaN value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender         25\n",
       "ethnicity    1395\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_df = df[['gender','ethnicity']]\n",
    "fill_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender       0\n",
       "ethnicity    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#backward fill\n",
    "fill_df['gender'].fillna(method='bfill',inplace = True)\n",
    "# Forward fill\n",
    "fill_df['ethnicity'].fillna(method='ffill',inplace = True)\n",
    "fill_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn Imputer for Numerical Variables  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer_skdf = df[['readmission_status','weight']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "readmission_status    0\n",
       "weight                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "# Fit and transform to the parameters\n",
    "imputer_skdf = pd.DataFrame(imputer.fit_transform(imputer_skdf))\n",
    "imputer_skdf.columns = ['readmission_status','weight']\n",
    "# Checking for any null values\n",
    "imputer_skdf.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn Imputer for Categorical Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICU Stay Type - value Counts : \n",
      "  Caucasian           70684\n",
      "African American     9547\n",
      "Other/Unknown        4374\n",
      "Hispanic             3796\n",
      "Asian                1129\n",
      "Native American       788\n",
      "Name: ethnicity, dtype: int64\n",
      "ICU Type - value Counts : \n",
      "  M    49469\n",
      "F    42219\n",
      "Name: gender, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "categ_df = df[['ethnicity','gender']]\n",
    "print(\"ICU Stay Type - value Counts : \\n \" ,categ_df['ethnicity'].value_counts())\n",
    "print(\"ICU Type - value Counts : \\n \" , categ_df['gender'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICU Stay Type - value Counts : \n",
      "  Caucasian           72079\n",
      "African American     9547\n",
      "Other/Unknown        4374\n",
      "Hispanic             3796\n",
      "Asian                1129\n",
      "Native American       788\n",
      "Name: ethnicity, dtype: int64\n",
      "ICU Type - value Counts : \n",
      "  M    49494\n",
      "F    42219\n",
      "Name: gender, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Replacing null values in Embarked with most frequent value\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "categ_df = pd.DataFrame(imputer.fit_transform(categ_df))\n",
    "categ_df.columns =['ethnicity','gender']\n",
    "# Value counts for Embarked column\n",
    "print(\"ICU Stay Type - value Counts : \\n \" ,categ_df['ethnicity'].value_counts())\n",
    "print(\"ICU Type - value Counts : \\n \" , categ_df['gender'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ethnicity    0\n",
       "gender       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categ_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference :\n",
    "\n",
    "https://medium.com/bycodegarage/a-comprehensive-guide-on-handling-missing-values-b1257a4866d1\n",
    "\n",
    "https://analyticsindiamag.com/5-ways-handle-missing-values-machine-learning-datasets/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
